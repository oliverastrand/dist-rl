import tensorflow as tf

from abc import ABC, abstractmethod


class Learner(ABC):

    def __init__(self, observation_shape, nr_actions, alpha=0.01):

        # Create the tensorflow graph and needed operations
        self.alpha = alpha

        self.observation_shape = observation_shape
        self.nr_actions = nr_actions

        self.states = tf.placeholder(dtype=tf.float32, shape=(None,) + observation_shape)
        self.targets = tf.placeholder(dtype=tf.float32, shape=(None, nr_actions))

        self.predictions, self.weight_list = self.init_neural_net(self.states)

        loss = tf.losses.mean_squared_error(labels=self.targets, predictions=self.predictions)

        optimizer = tf.train.AdamOptimizer(learning_rate=self.alpha)
        self.train_op = optimizer.minimize(loss=loss)

        self.target_predictions, self.target_weight_list = self.init_neural_net(self.states)

        self.init_op = tf.global_variables_initializer()

    # Initallize the parameters with a given session
    def init_params(self, sess):
        sess.run(self.init_op)

    # Predict Q-values with the regular network
    def predict(self, state, sess):
        return sess.run(self.predictions, feed_dict={self.states: state})

    # Predict the Q-values with the target network
    def predict_targets(self, state, sess):
        return sess.run(self.target_predictions, feed_dict={self.states: state})

    # Fit the network to data generated by the Bellman Eq.
    def fit(self, states, targets, sess):
        sess.run(self.train_op, feed_dict={self.states: states, self.targets: targets})

    # Method for designing the neural network, implemented by each subclass.
    @abstractmethod
    def init_neural_net(self, input_values):
        return None, None
